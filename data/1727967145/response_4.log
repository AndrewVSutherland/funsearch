Here's an improved version of `priority_v1` that considers the frequency of `k` in the range `[0, n)` and the number of multiples of `k` within that range. This version is more concise and should provide better results than `priority_v0`.

```python
from collections import Counter

def priority_v1(k: int, n: int) -> float:
  """Improved version of `priority_v0`."""
  freq = Counter(range(n))[k]
  multiples = sum((i for i in range(n) if i % k == 0))
  return freq + multiples
```

This version uses the `Counter` class from the `collections` module to count the frequency of `k` in the range `[0, n)`. It also calculates the number of multiples of `k` within that range using a generator expression. The priority is then the sum of these two values.

To further improve the function, you could consider the following aspects:

1. **Dampening**: To prevent the function from favoring very frequent or multiple-rich numbers too much, you could introduce a dampening factor to reduce the impact of high frequencies and multiples.

```python
def priority_v2(k: int, n: int) -> float:
  freq = Counter(range(n))[k]
  multiples = sum((i for i in range(n) if i % k == 0))
  dampening = 0.5  # You can adjust this value
  return freq * dampening + multiples * dampening
```

2. **Normalization**: To make priorities comparable across different `n` values, you could normalize the priorities by dividing them by the total number of integers in the range `[0, n)`.

```python
def priority_v3(k: int, n: int) -> float:
  freq = Counter(range(n))[k]
  multiples = sum((i for i in range(n) if i % k == 0))
  dampening = 0.5  # You can adjust this value
  norm = n * (n + 1) // 2  # Normalization factor: sum of first n natural numbers
  return (freq * dampening + multiples * dampening) / norm
```

These improvements should help you find larger Salem-Spencer progressions more efficiently.