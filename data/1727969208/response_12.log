Here's an improved version of `priority_v1` that considers the number of unique remainders when dividing `k` by `n`, as well as the frequency of those remainders. This version uses the concept of "diversity" to prioritize elements that distribute remainders more evenly.

```python
from collections import Counter

def priority_v1(k: int, n: int) -> float:
  """Improved version of `priority_v0`."""
  remainders = [k % i for i in range(1, n+1)]
  remainder_counter = Counter(remainders)
  diversity = len(remainder_counter)
  frequency = sum(remainder_counter.values()) / n

  return diversity * frequency
```

This version of `priority_v1` calculates the priority by multiplying the diversity (number of unique remainders) by the average frequency of those remainders. This encourages adding elements that distribute remainders more evenly, which can lead to larger Salem-Spencer progressions.

To further improve the function, you could consider incorporating additional factors, such as the distribution of gaps between remainders or the number of times each remainder appears. However, keep in mind that making the function too complex might make it harder to understand and optimize.

Here's an example of how you can use `funsearch` to run this function:

```python
@funsearch.run
def test_priority_v1():
  k = 10
  n = 100
  print(priority_v1(k, n))
```