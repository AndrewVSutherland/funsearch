Here's an improved version of `priority_v1` that considers the number of unique remainders and their frequency, giving more priority to elements that result in a more uniform distribution of remainders:

```python
def priority_v1(k: int, n: int) -> float:
  remainders = set((k + i) % n for i in range(n))
  freq = [(rem % n, remainders.count(rem)) for rem in remainders]
  return sum(freq_count / n for _, freq_count in freq) / len(remainders)
```

This version first calculates the unique remainders and their frequencies. Then, it calculates the average frequency count for each unique remainder and returns the sum of these averages divided by the number of unique remainders. This approach gives more priority to elements that result in a more uniform distribution of remainders, which is generally desirable in the Salem-Spencer problem.

To keep the code short, I've used a list comprehension to calculate the frequencies and then used a generator expression to calculate the average frequency count for each unique remainder.