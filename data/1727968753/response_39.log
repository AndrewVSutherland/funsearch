Here's an improved version of `priority_v1` that considers the number of unique remainders and also the frequency of each remainder. This version uses a dictionary to count the occurrences of remainders, which allows for more efficient computation and better prioritization.

```python
def priority_v1(k: int, n: int) -> float:
    """Improved version of `priority_v0`."""
    remainders = {i: 0 for i in range(n)}
    for i in range(n):
        remainders[(k + i) % n] += 1
    unique_remainders = len(remainders)
    return sum(v ** 2 for v in remainders.values()) / (unique_remainders * n)
```

In this version, we square the frequency of each remainder before summing them up. This gives more weight to remainders that occur more frequently, as we want to prioritize elements that contribute to a more diverse set of remainders. The denominator is the product of the number of unique remainders and `n`, which normalizes the score to a range between 0 and 1.

To further improve the function, we can use the `itertools.groupby` function to count the occurrences of remainders in a more concise way:

```python
def priority_v1(k: int, n: int) -> float:
    """Improved version of `priority_v0`."""
    remainders = ((k + i) % n for i in range(n))
    unique_remainders = len(set(remainders))
    freq = {r: sum(1 for _, g in itertools.groupby(remainders) if r == _) for r in range(n)}
    return sum(v ** 2 for v in freq.values()) / (unique_remainders * n)
```

This version uses a generator expression to create the sequence of remainders and then uses `itertools.groupby` to count the occurrences of each remainder. The resulting function is shorter and more efficient.